{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Churn\n",
    "\n",
    "One of the important applications of classification techniques in marketing analytics lies in predicting whether\n",
    "individual customers will defect to a competitor over a fixed time period (e.g. over the next year). Your goal is to\n",
    "build the best model possible to predict churn. In this problem you will use the “churn_data.csv” file to make these\n",
    "kinds of predictions, and you will implement a Jupyter notebook to accomplish this. Please make sure your Jupyter\n",
    "notebook addresses the questions with appropriate discussion (i.e. you will want to include appropriate discussion\n",
    "around your code).\n",
    "\n",
    "Load the “churn_data.csv” dataset into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import ensemble #Contains random forest algorithm\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CustID  Gender  Age Income  FamilySize  Education  Calls  Visits Churn\n",
      "0   123251    Male   34  Lower           4         16     14       5   Yes\n",
      "1   188922    Male   20  Lower           5         14     49       1    No\n",
      "2   145322  Female   30  Lower           4         20     19       4   Yes\n",
      "3   153729  Female   46  Lower           4         14     15       4   Yes\n",
      "4   103976  Female   23  Lower           4         16     18       0    No\n",
      "5   139389    Male   54  Upper           3         12      6       0    No\n",
      "6   197395  Female   32  Upper           3         17     22       0    No\n",
      "7   176036  Female   19  Lower           1         12      8       1    No\n",
      "8   139348    Male   34  Lower           3         12     11       3    No\n",
      "9   151276  Female   18  Upper           4         16     11       1   Yes\n",
      "10  102056  Female   17  Upper           1         12     25       1    No\n",
      "11  118692    Male   29  Lower           4         16     29       1   Yes\n",
      "12  103866  Female   30  Upper           2         12     26       1    No\n",
      "13  160978    Male   25  Upper           2         18     40       0   Yes\n",
      "14  179953  Female   68  Lower           4         14     36       0    No\n",
      "15  143741  Female   58  Upper           2         15     20       0    No\n",
      "16  187711    Male   25  Lower           2         14     16       1   Yes\n",
      "17  130677  Female   64  Upper           2         17     12       3    No\n",
      "18  173103  Female   60  Lower           3         16     20       5   Yes\n",
      "19  165705    Male   43  Lower           3         16      8       4    No\n",
      " \n",
      "   CustID  Gender  Age Income  FamilySize  Education  Calls  Visits Churn\n",
      "0  102522    Male   54  Upper           4         18     48       3   Yes\n",
      "1  108050    Male   21  Lower           4         19     44       2   Yes\n",
      "2  108118  Female   22  Lower           3         16     22       5   Yes\n",
      "3  109501    Male   27  Upper           3         13     19       2   Yes\n",
      "4  109782    Male   18  Lower           2         14      6       3    No\n"
     ]
    }
   ],
   "source": [
    "#Read in data\n",
    "data = pd.read_csv('C:/Github/DSCI-402-2019/data_files/churn_data.csv')\n",
    "validation = pd.read_csv('C:/Github/DSCI-402-2019/data_files/churn_validation.csv')\n",
    "\n",
    "print(data.head(20))\n",
    "print(' ')\n",
    "print(validation.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) What is the response variable, and what are the predictor variables?**\n",
    "\n",
    "Our response variable is the Churn variable which shows whether or not the individual remained a customer. The rest of the columns are considered the predictor variables, however the data does need some cleaning before we can make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) What data transforms are necessary to perform on this data and why?**\n",
    "\n",
    "The CustID column can be dropped because it is just added noise and has no effect on the Churn of the customer. We can also make changes to \"Gender\", \"Income\", and \"Churn\". Female and Male in \"Gender\" can be changed to 1 and 0. Upper and Lower in \"Income\" can be changed to 1 and 0. Yes and No in \"Churn\" can be changed to 1 and 0.  These changes will make it easier to implement predicting models. (I made these changes to both the churn data and the validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete CustID column\n",
    "del data['CustID']\n",
    "del validation['CustID']\n",
    "\n",
    "#Change the yes and no in churn, then female and male in gender, and the upper and lower in income into 1 and 0 (For the data set)\n",
    "yes = data['Churn'] == 'Yes'\n",
    "data.loc[yes, 'Churn'] = 1\n",
    "\n",
    "no = data['Churn'] == 'No'\n",
    "data.loc[no, 'Churn'] = 0\n",
    "\n",
    "\n",
    "female = data['Gender'] == 'Female'\n",
    "data.loc[female, 'Gender'] = 1\n",
    "\n",
    "male = data['Gender'] == 'Male'\n",
    "data.loc[male, 'Gender'] = 0\n",
    "\n",
    "upper = data['Income'] == 'Upper'\n",
    "data.loc[upper, 'Income'] = 1\n",
    "\n",
    "lower = data['Income'] == 'Lower'\n",
    "data.loc[lower, 'Income'] = 0\n",
    "\n",
    "#Make the same changes to the validation set\n",
    "yes = validation['Churn'] == 'Yes'\n",
    "validation.loc[yes, 'Churn'] = 1\n",
    "\n",
    "no = validation['Churn'] == 'No'\n",
    "validation.loc[no, 'Churn'] = 0\n",
    "\n",
    "female = validation['Gender'] == 'Female'\n",
    "validation.loc[female, 'Gender'] = 1\n",
    "\n",
    "male = validation['Gender'] == 'Male'\n",
    "validation.loc[male, 'Gender'] = 0\n",
    "\n",
    "upper = validation['Income'] == 'Upper'\n",
    "validation.loc[upper, 'Income'] = 1\n",
    "\n",
    "lower = validation['Income'] == 'Lower'\n",
    "validation.loc[lower, 'Income'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data to see relationships of variables. \n",
    "sm = pd.plotting.scatter_matrix(data, diagonal = 'kde', figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) What modeling approaches did you use and why? Describe your model development process, including the different models tried, feature selection methods, and the different transformation techniques you employed.**\n",
    "\n",
    "When doing my analysis, I decided to use all remaining features because even though there is some correlation think they all stand independently enough to bring unique information to our analysis. I used 5 modeling approaches to analyze this data because more models increase our chance of finding the best one. Each model will be explained as it is used. \n",
    "\n",
    "While doing the analysis, I used the churn data first and split it into training and testing sets. I used this data to find the best predictor model of the ones that I tried. Once I found the best model, I imported the validation data to run more tests. I then used all of the churn data as my training set and the validation data as my test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictors - all non-Churn columns (Churn is the last column)\n",
    "data_x = data[list(data)[:-1]]\n",
    "val_x = validation[list(validation)[:-1]]\n",
    "\n",
    "#Get target variable y - Churn column\n",
    "data_y = data['Churn']\n",
    "val_y = validation['Churn']\n",
    "\n",
    "\n",
    "#Split data into training and test sets (comment this out once you have picked the best model)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size = 0.3, random_state=4)\n",
    "\n",
    "#Split data into training and test sets(uncomment these so that the validation data can be ran)\n",
    "#x_train = data_x\n",
    "#y_train = data_y\n",
    "#x_test = val_x\n",
    "#y_test = val_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression **\n",
    "\n",
    "Logistic Regression is used to predict the odds of being a case based on the values of the predictors. The odds are definedas a probability that a particular outcome is a case divided by the probability that it is a noncase. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a logistic regression model\n",
    "log_mod = linear_model.LogisticRegression()\n",
    "log_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>P(X=1)</th>\n",
       "      <th>P(x=1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546568</td>\n",
       "      <td>0.546568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612982</td>\n",
       "      <td>0.612982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584210</td>\n",
       "      <td>0.584210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717188</td>\n",
       "      <td>0.717188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488857</td>\n",
       "      <td>0.488857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465782</td>\n",
       "      <td>0.465782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435685</td>\n",
       "      <td>0.435685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.424309</td>\n",
       "      <td>0.424309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239364</td>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.824521</td>\n",
       "      <td>0.824521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418850</td>\n",
       "      <td>0.418850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389847</td>\n",
       "      <td>0.389847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446575</td>\n",
       "      <td>0.446575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.393506</td>\n",
       "      <td>0.393506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201994</td>\n",
       "      <td>0.201994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Predicted Class    P(X=1)    P(x=1)\n",
       "5        0                1  0.546568  0.546568\n",
       "24       1                1  0.612982  0.612982\n",
       "29       1                1  0.584210  0.584210\n",
       "61       1                1  0.717188  0.717188\n",
       "19       0                0  0.488857  0.488857\n",
       "95       1                0  0.465782  0.465782\n",
       "2        1                0  0.435685  0.435685\n",
       "25       0                0  0.424309  0.424309\n",
       "90       0                0  0.239364  0.239364\n",
       "78       1                1  0.824521  0.824521\n",
       "12       0                0  0.418850  0.418850\n",
       "74       0                0  0.389847  0.389847\n",
       "34       1                0  0.446575  0.446575\n",
       "16       1                0  0.393506  0.393506\n",
       "20       0                0  0.201994  0.201994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make predictions\n",
    "preds = log_mod.predict(x_test)  #Get predicted labels\n",
    "pred_probs = log_mod.predict_proba(x_test)   #Get predicted probabilities/ Each observation is a 2-element array.\n",
    "pred_pos = pred_probs.transpose()[1]  #P(X = 1) is column 1\n",
    "pred_neg = pred_probs.transpose()[1]  #P(X = 0) is column 0\n",
    "\n",
    "#Look at results\n",
    "pred_df = pd.DataFrame({\"Actual\": y_test, \"Predicted Class\": preds, \"P(X=1)\" : pred_pos, \"P(x=1)\": pred_neg})\n",
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Which error metrics did you use to assess performance and why? What kind of performance did you obtain on the different models you built?**\n",
    "\n",
    "To asses the performance of the models, I used accuracy, precision, recall, F1, Roc Auc and a confusion matrix in order to get the whole picture of the model. \n",
    "**Accuracy:** Total % correctly classified\n",
    "\n",
    "**Precision:** % predicted positive that are correctly called positive\n",
    "\n",
    "**Recall:** % predicted positive out of all positive\n",
    "\n",
    "**F1 Score:** Mean of Precision and Recall\n",
    "\n",
    "**Roc Auc:** Plots false positive and true positive \n",
    "\n",
    "**Confusion Matrix:** Shows actual classes in rows and predicted classes in column to visualize the correct predictions and misclassifications to be clearly seen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7435897435897436\n",
      "Precision:  0.8235294117647058\n",
      "Recall:  0.6666666666666666\n",
      "F1:  0.7368421052631577\n",
      "ROC AUC:  0.75\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 7 14]]\n"
     ]
    }
   ],
   "source": [
    "#Look at error metrics\n",
    "print(\"Accuracy:  \" + str(accuracy_score(y_test, preds)))\n",
    "print(\"Precision:  \" + str(precision_score(y_test, preds)))\n",
    "print(\"Recall:  \" + str(recall_score(y_test, preds)))\n",
    "print(\"F1:  \" + str(f1_score(y_test, preds)))\n",
    "print(\"ROC AUC:  \" + str(roc_auc_score(y_test, preds)))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors Example**\n",
    "\n",
    "The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------EVALUATING MODEL k = 2---------------------------\n",
      "Accuracy:  0.6410256410256411\n",
      "Precision:  0.7692307692307693\n",
      "Recall:  0.47619047619047616\n",
      "F1:  0.588235294117647\n",
      "ROC AUC:  0.6547619047619048\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [11 10]]\n",
      "-------------------EVALUATING MODEL k = 3---------------------------\n",
      "Accuracy:  0.6923076923076923\n",
      "Precision:  0.6956521739130435\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.7272727272727272\n",
      "ROC AUC:  0.6865079365079365\n",
      "Confusion Matrix: \n",
      "[[11  7]\n",
      " [ 5 16]]\n",
      "-------------------EVALUATING MODEL k = 7---------------------------\n",
      "Accuracy:  0.5897435897435898\n",
      "Precision:  0.6086956521739131\n",
      "Recall:  0.6666666666666666\n",
      "F1:  0.6363636363636365\n",
      "ROC AUC:  0.5833333333333333\n",
      "Confusion Matrix: \n",
      "[[ 9  9]\n",
      " [ 7 14]]\n",
      "-------------------EVALUATING MODEL k = 11---------------------------\n",
      "Accuracy:  0.6153846153846154\n",
      "Precision:  0.625\n",
      "Recall:  0.7142857142857143\n",
      "F1:  0.6666666666666666\n",
      "ROC AUC:  0.6071428571428572\n",
      "Confusion Matrix: \n",
      "[[ 9  9]\n",
      " [ 6 15]]\n",
      "-------------------EVALUATING MODEL k = 13---------------------------\n",
      "Accuracy:  0.6153846153846154\n",
      "Precision:  0.6363636363636364\n",
      "Recall:  0.6666666666666666\n",
      "F1:  0.6511627906976744\n",
      "ROC AUC:  0.6111111111111112\n",
      "Confusion Matrix: \n",
      "[[10  8]\n",
      " [ 7 14]]\n",
      "-------------------EVALUATING MODEL k = 15---------------------------\n",
      "Accuracy:  0.5897435897435898\n",
      "Precision:  0.6\n",
      "Recall:  0.7142857142857143\n",
      "F1:  0.6521739130434783\n",
      "ROC AUC:  0.5793650793650794\n",
      "Confusion Matrix: \n",
      "[[ 8 10]\n",
      " [ 6 15]]\n",
      "-------------------EVALUATING MODEL k = 17---------------------------\n",
      "Accuracy:  0.6153846153846154\n",
      "Precision:  0.6153846153846154\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.6808510638297872\n",
      "ROC AUC:  0.6031746031746031\n",
      "Confusion Matrix: \n",
      "[[ 8 10]\n",
      " [ 5 16]]\n",
      "-------------------EVALUATING MODEL k = 19---------------------------\n",
      "Accuracy:  0.5384615384615384\n",
      "Precision:  0.5555555555555556\n",
      "Recall:  0.7142857142857143\n",
      "F1:  0.6250000000000001\n",
      "ROC AUC:  0.5238095238095238\n",
      "Confusion Matrix: \n",
      "[[ 6 12]\n",
      " [ 6 15]]\n",
      "-------------------EVALUATING MODEL k = 21---------------------------\n",
      "Accuracy:  0.5384615384615384\n",
      "Precision:  0.5483870967741935\n",
      "Recall:  0.8095238095238095\n",
      "F1:  0.6538461538461537\n",
      "ROC AUC:  0.5158730158730158\n",
      "Confusion Matrix: \n",
      "[[ 4 14]\n",
      " [ 4 17]]\n"
     ]
    }
   ],
   "source": [
    "#Build a sequence of models for a set of different k values.\n",
    "ks = [2, 3, 7, 11, 13, 15, 17, 19, 21]\n",
    "for k in ks:\n",
    "    #Create and fit a KNN model \n",
    "    mod = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "    mod.fit(x_train, y_train)\n",
    "    \n",
    "    #Make predictions and evaluate\n",
    "    preds = mod.predict(x_test)\n",
    "    print('-------------------EVALUATING MODEL k = ' + str(k) + '---------------------------')\n",
    "    #Look at error metrics\n",
    "    print(\"Accuracy:  \" + str(accuracy_score(y_test, preds)))\n",
    "    print(\"Precision:  \" + str(precision_score(y_test, preds)))\n",
    "    print(\"Recall:  \" + str(recall_score(y_test, preds)))\n",
    "    print(\"F1:  \" + str(f1_score(y_test, preds)))\n",
    "    print(\"ROC AUC:  \" + str(roc_auc_score(y_test, preds)))\n",
    "    print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Classifier**\n",
    "\n",
    " A Naive Bayes Classifier assumes that the value of a particular feature is independent of the value of any other feature, given the class variable. All features contribute independently in the classification of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------EVALUATING GAUSSIAN NAIVE BAYES MODEL---------\n",
      "Accuracy:  0.7692307692307693\n",
      "Precision:  0.8333333333333334\n",
      "Recall:  0.7142857142857143\n",
      "F1:  0.7692307692307692\n",
      "ROC AUC:  0.773809523809524\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 6 15]]\n",
      " \n",
      "-------EVALUATING BERNOULLI NAIVE BAYES MODEL---------\n",
      "Accuracy:  0.7692307692307693\n",
      "Precision:  0.8333333333333334\n",
      "Recall:  0.7142857142857143\n",
      "F1:  0.7692307692307692\n",
      "ROC AUC:  0.773809523809524\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 6 15]]\n"
     ]
    }
   ],
   "source": [
    "#Building Gaussian Naive Bayes Model\n",
    "gnb_mod = naive_bayes.GaussianNB()\n",
    "gnb_mod.fit(x_train,y_train)\n",
    "preds = gnb_mod.predict(x_test)\n",
    "\n",
    "print(\"-------EVALUATING GAUSSIAN NAIVE BAYES MODEL---------\")\n",
    "#Look at error metrics\n",
    "print(\"Accuracy:  \" + str(accuracy_score(y_test, preds)))\n",
    "print(\"Precision:  \" + str(precision_score(y_test, preds)))\n",
    "print(\"Recall:  \" + str(recall_score(y_test, preds)))\n",
    "print(\"F1:  \" + str(f1_score(y_test, preds)))\n",
    "print(\"ROC AUC:  \" + str(roc_auc_score(y_test, preds)))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, preds)))\n",
    "\n",
    "\n",
    "#Building Bernoulli Naive Bayes Model\n",
    "bnb_mod = naive_bayes.BernoulliNB()\n",
    "bnb_mod.fit(x_train,y_train)\n",
    "preds = gnb_mod.predict(x_test)\n",
    "\n",
    "print(\" \")\n",
    "print(\"-------EVALUATING BERNOULLI NAIVE BAYES MODEL---------\")\n",
    "#Look at error metrics\n",
    "print(\"Accuracy:  \" + str(accuracy_score(y_test, preds)))\n",
    "print(\"Precision:  \" + str(precision_score(y_test, preds)))\n",
    "print(\"Recall:  \" + str(recall_score(y_test, preds)))\n",
    "print(\"F1:  \" + str(f1_score(y_test, preds)))\n",
    "print(\"ROC AUC:  \" + str(roc_auc_score(y_test, preds)))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**\n",
    "\n",
    "This classifier constructs multiple decision trees. Each tree will make a prediction of the class and output the mode of all predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- EVALUATING RANDOM FOREST: n_estimators = 5, max_depth = 3 -----\n",
      "Accuracy:  0.7948717948717948\n",
      "Precision:  0.8095238095238095\n",
      "Recall:  0.8095238095238095\n",
      "F1:  0.8095238095238095\n",
      "ROC AUC:  0.7936507936507937\n",
      "Confusion Matrix: \n",
      "[[14  4]\n",
      " [ 4 17]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 5, max_depth = 6 -----\n",
      "Accuracy:  0.8461538461538461\n",
      "Precision:  0.9411764705882353\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.8421052631578947\n",
      "ROC AUC:  0.8531746031746031\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 5 16]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 5, max_depth = None -----\n",
      "Accuracy:  0.7948717948717948\n",
      "Precision:  0.8421052631578947\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.8\n",
      "ROC AUC:  0.7976190476190477\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 5 16]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 10, max_depth = 3 -----\n",
      "Accuracy:  0.7692307692307693\n",
      "Precision:  0.875\n",
      "Recall:  0.6666666666666666\n",
      "F1:  0.7567567567567567\n",
      "ROC AUC:  0.7777777777777777\n",
      "Confusion Matrix: \n",
      "[[16  2]\n",
      " [ 7 14]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 10, max_depth = 6 -----\n",
      "Accuracy:  0.8717948717948718\n",
      "Precision:  1.0\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.8648648648648648\n",
      "ROC AUC:  0.8809523809523809\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 5 16]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 10, max_depth = None -----\n",
      "Accuracy:  0.8205128205128205\n",
      "Precision:  0.9375\n",
      "Recall:  0.7142857142857143\n",
      "F1:  0.8108108108108109\n",
      "ROC AUC:  0.8293650793650794\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 6 15]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 50, max_depth = 3 -----\n",
      "Accuracy:  0.7948717948717948\n",
      "Precision:  0.8823529411764706\n",
      "Recall:  0.7142857142857143\n",
      "F1:  0.7894736842105262\n",
      "ROC AUC:  0.8015873015873016\n",
      "Confusion Matrix: \n",
      "[[16  2]\n",
      " [ 6 15]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 50, max_depth = 6 -----\n",
      "Accuracy:  0.8974358974358975\n",
      "Precision:  1.0\n",
      "Recall:  0.8095238095238095\n",
      "F1:  0.8947368421052632\n",
      "ROC AUC:  0.9047619047619048\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 4 17]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 50, max_depth = None -----\n",
      "Accuracy:  0.8205128205128205\n",
      "Precision:  0.8888888888888888\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.8205128205128205\n",
      "ROC AUC:  0.8253968253968254\n",
      "Confusion Matrix: \n",
      "[[16  2]\n",
      " [ 5 16]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 100, max_depth = 3 -----\n",
      "Accuracy:  0.8205128205128205\n",
      "Precision:  0.8888888888888888\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.8205128205128205\n",
      "ROC AUC:  0.8253968253968254\n",
      "Confusion Matrix: \n",
      "[[16  2]\n",
      " [ 5 16]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 100, max_depth = 6 -----\n",
      "Accuracy:  0.8717948717948718\n",
      "Precision:  1.0\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.8648648648648648\n",
      "ROC AUC:  0.8809523809523809\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 5 16]]\n",
      "----- EVALUATING RANDOM FOREST: n_estimators = 100, max_depth = None -----\n",
      "Accuracy:  0.8717948717948718\n",
      "Precision:  1.0\n",
      "Recall:  0.7619047619047619\n",
      "F1:  0.8648648648648648\n",
      "ROC AUC:  0.8809523809523809\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 5 16]]\n"
     ]
    }
   ],
   "source": [
    "#trying different estimators for this one than the last few\n",
    "#Build a sequence of random forest models for different numbers of estimators and tree depths.\n",
    "n_est = [5, 10, 50, 100] #number of trees\n",
    "depths = [3, 6, None]#how many nods to go into. None is the default depth\n",
    "\n",
    "#for each estimator try each depth. have to do a forloop\n",
    "\n",
    "for n in n_est:\n",
    "    for depth in depths:\n",
    "        mod = ensemble.RandomForestClassifier(n_estimators = n, max_depth= depth)\n",
    "        mod.fit(x_train, y_train)\n",
    "        preds = mod.predict(x_test)\n",
    "\n",
    "        #Look at error metrics\n",
    "        print(\"----- EVALUATING RANDOM FOREST: n_estimators = \" + str(n) + \", max_depth = \" + str(depth) + \" -----\")\n",
    "        print(\"Accuracy:  \" + str(accuracy_score(y_test, preds)))\n",
    "        print(\"Precision:  \" + str(precision_score(y_test, preds)))\n",
    "        print(\"Recall:  \" + str(recall_score(y_test, preds)))\n",
    "        print(\"F1:  \" + str(f1_score(y_test, preds)))\n",
    "        print(\"ROC AUC:  \" + str(roc_auc_score(y_test, preds)))\n",
    "        print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine Classifier**\n",
    "\n",
    "This classifier creates a line or a hyperplane which seperates the data into classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------EVALUATING SUPPORT VECTOR: C = 0.2 --------------------\n",
      "Accuracy:  0.5384615384615384\n",
      "Precision:  0.5384615384615384\n",
      "Recall:  1.0\n",
      "F1:  0.7000000000000001\n",
      "ROC AUC:  0.5\n",
      "Confusion Matrix: \n",
      "[[ 0 18]\n",
      " [ 0 21]]\n",
      "--------------------------EVALUATING SUPPORT VECTOR: C = 0.5 --------------------\n",
      "Accuracy:  0.5384615384615384\n",
      "Precision:  0.5384615384615384\n",
      "Recall:  1.0\n",
      "F1:  0.7000000000000001\n",
      "ROC AUC:  0.5\n",
      "Confusion Matrix: \n",
      "[[ 0 18]\n",
      " [ 0 21]]\n",
      "--------------------------EVALUATING SUPPORT VECTOR: C = 1.0 --------------------\n",
      "Accuracy:  0.5641025641025641\n",
      "Precision:  0.5555555555555556\n",
      "Recall:  0.9523809523809523\n",
      "F1:  0.7017543859649122\n",
      "ROC AUC:  0.5317460317460317\n",
      "Confusion Matrix: \n",
      "[[ 2 16]\n",
      " [ 1 20]]\n",
      "--------------------------EVALUATING SUPPORT VECTOR: C = 2.0 --------------------\n",
      "Accuracy:  0.5897435897435898\n",
      "Precision:  0.5714285714285714\n",
      "Recall:  0.9523809523809523\n",
      "F1:  0.7142857142857142\n",
      "ROC AUC:  0.5595238095238094\n",
      "Confusion Matrix: \n",
      "[[ 3 15]\n",
      " [ 1 20]]\n",
      "--------------------------EVALUATING SUPPORT VECTOR: C = 5.0 --------------------\n",
      "Accuracy:  0.5897435897435898\n",
      "Precision:  0.5714285714285714\n",
      "Recall:  0.9523809523809523\n",
      "F1:  0.7142857142857142\n",
      "ROC AUC:  0.5595238095238094\n",
      "Confusion Matrix: \n",
      "[[ 3 15]\n",
      " [ 1 20]]\n",
      "--------------------------EVALUATING SUPPORT VECTOR: C = 10.0 --------------------\n",
      "Accuracy:  0.5897435897435898\n",
      "Precision:  0.5714285714285714\n",
      "Recall:  0.9523809523809523\n",
      "F1:  0.7142857142857142\n",
      "ROC AUC:  0.5595238095238094\n",
      "Confusion Matrix: \n",
      "[[ 3 15]\n",
      " [ 1 20]]\n"
     ]
    }
   ],
   "source": [
    "#Build a sequence of SVM models for different C values.\n",
    "cs = [0.2, 0.5, 1.0, 2.0, 5.0, 10.0] #1.0 is default\n",
    "\n",
    "for c in cs:\n",
    "    mod = svm.SVC(C=c)\n",
    "    mod.fit(x_train, y_train)\n",
    "    preds = mod.predict(x_test)\n",
    "\n",
    "    #Look at error metrics\n",
    "    print(\"--------------------------EVALUATING SUPPORT VECTOR: C = \" + str(c) + \" --------------------\")\n",
    "    print(\"Accuracy:  \" + str(accuracy_score(y_test, preds)))\n",
    "    print(\"Precision:  \" + str(precision_score(y_test, preds)))\n",
    "    print(\"Recall:  \" + str(recall_score(y_test, preds)))\n",
    "    print(\"F1:  \" + str(f1_score(y_test, preds)))\n",
    "    print(\"ROC AUC:  \" + str(roc_auc_score(y_test, preds)))\n",
    "    print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Construct the best (i.e. least-error) possible model on this data set. What are the predictors used?**\n",
    "\n",
    "Using the churn data, the best model turned out to be the Random Forest Model with an n_estimator = 5 and a maxdepth = None using all the features as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Load the dataset “churn_validation.csv” into a new data frame and recode as necessary. Predict the outcomes for each of the customers and compare to the actual. What are the error rates you get based on your selected metrics?**\n",
    "\n",
    "When running the validation data through the 'best model', the error did increase, but it still had the least error. However different n_estimators and maxdepths gave the least error for the validation than the original test data. \n",
    "\n",
    "----- EVALUATING RANDOM FOREST: n_estimators = 50, max_depth = 3 -----\n",
    "\n",
    "Accuracy:  0.71875\n",
    "\n",
    "Precision:  0.6111111111111112\n",
    "\n",
    "Recall:  0.8461538461538461\n",
    "\n",
    "F1:  0.7096774193548387\n",
    "\n",
    "ROC AUC:  0.7388663967611335\n",
    "\n",
    "Confusion Matrix: \n",
    "\n",
    "[[12  7]\n",
    "\n",
    "[ 2 11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Consider the best model you built for this problem. Is it a good model that can reliably be used for prediction? Why or why not?**\n",
    "For this data set, it is a good model because it can handle missing data and irrelevant features, is one of the best-performing ML algorithms, it can provide feature and importance ratings easily, and this is a small set of data. If we had a larger set of data, a different algorithm may be more usefule since the random forest can be slow to train and may need parameter adjustments to acheive its best performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
